using System.Text;
using System.Text.Json;
using AIAgentFramework.Tools.BuiltIn.Echo;
using AIAgentFramework.Tools.BuiltIn.FileReader;
using AIAgentFramework.Tools.BuiltIn.FileWriter;
using AIAgentFramework.Tools.BuiltIn.DirectoryReader;
using AIAgentFramework.Tools.BuiltIn.DirectoryCreator;
using AIAgentFramework.Tools.Models;
using AIAgentFramework.LLM.Providers;
using AIAgentFramework.LLM.Models;
using AIAgentFramework.LLM.Abstractions;
using AIAgentFramework.LLM.Services.ToolSelection;
using AIAgentFramework.LLM.Services.Planning;
using CoreModels = AIAgentFramework.Core.Models;

// ì½˜ì†” UTF-8 ì¸ì½”ë”© ì„¤ì •
Console.OutputEncoding = Encoding.UTF8;

// ========================================
// ê³µí†µ ì´ˆê¸°í™”
// ========================================

var ollama = new OllamaProvider("http://192.168.25.50:11434", "gpt-oss:20b");
var toolRegistry = new ToolRegistry();

// ê¸°ë³¸ Tool ë“±ë¡
toolRegistry.Register(new EchoTool());
toolRegistry.Register(new FileReaderTool());
toolRegistry.Register(new FileWriterTool());
toolRegistry.Register(new DirectoryReaderTool());
toolRegistry.Register(new DirectoryCreatorTool());

var templatesPath = @"c:\src\work\ai\ai-agent-framework\src\Core\AIAgentFramework.LLM\Templates";
var promptRegistry = new PromptRegistry(templatesPath);

var llmRegistry = new LLMRegistry();

// ========================================
// ë©”ì¸ ë©”ë‰´
// ========================================

while (true)
{
    Console.Clear();
    Console.WriteLine("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    Console.WriteLine("â•‘   AI Agent Framework - í…ŒìŠ¤íŠ¸ ë©”ë‰´             â•‘");
    Console.WriteLine("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£");
    Console.WriteLine("â•‘  1. Ollama Provider í…ŒìŠ¤íŠ¸                     â•‘");
    Console.WriteLine("â•‘  2. PromptRegistry í…ŒìŠ¤íŠ¸                      â•‘");
    Console.WriteLine("â•‘  3. ToolSelectorFunction í…ŒìŠ¤íŠ¸                â•‘");
    Console.WriteLine("â•‘  4. Streaming í…ŒìŠ¤íŠ¸                           â•‘");
    Console.WriteLine("â•‘  5. TaskPlanner í…ŒìŠ¤íŠ¸                         â•‘");
    Console.WriteLine("â•‘  0. ì¢…ë£Œ                                        â•‘");
    Console.WriteLine("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    Console.Write("\nì„ íƒ: ");

    var choice = Console.ReadLine();

    try
    {
        switch (choice)
        {
            case "1":
                await TestOllamaProvider(ollama);
                break;
            case "2":
                await TestPromptRegistry(promptRegistry, toolRegistry, ollama);
                break;
            case "3":
                await TestToolSelector(promptRegistry, toolRegistry, ollama);
                break;
            case "4":
                await TestStreaming(promptRegistry, toolRegistry, ollama);
                break;
            case "5":
                await TestTaskPlanner(promptRegistry, toolRegistry, llmRegistry, ollama);
                break;
            case "0":
                Console.WriteLine("\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.");
                return;
            default:
                Console.WriteLine("\nì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.");
                break;
        }
    }
    catch (Exception ex)
    {
        Console.WriteLine($"\nì˜¤ë¥˜ ë°œìƒ: {ex.Message}");
    }

    Console.WriteLine("\n\nê³„ì†í•˜ë ¤ë©´ ì•„ë¬´ í‚¤ë‚˜ ëˆ„ë¥´ì„¸ìš”...");
    Console.ReadKey();
}

// ========================================
// í…ŒìŠ¤íŠ¸ ë©”ì„œë“œë“¤
// ========================================

static async Task TestOllamaProvider(OllamaProvider ollama)
{
    Console.Clear();
    Console.WriteLine("=== AI Agent Framework - Ollama Provider í…ŒìŠ¤íŠ¸ ===\n");

    Console.WriteLine($"Provider: {ollama.ProviderName}");
    Console.WriteLine($"Supported Models: {string.Join(", ", ollama.SupportedModels)}\n");

    Console.WriteLine("--- í…ŒìŠ¤íŠ¸ 1: ì¼ë°˜ í˜¸ì¶œ ---");
    var ollamaResponse = await ollama.CallAsync("Say hello in Korean!", "gpt-oss:20b");
    Console.WriteLine($"ì‘ë‹µ: {ollamaResponse}\n");

    Console.WriteLine("--- í…ŒìŠ¤íŠ¸ 2: ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ ---");
    Console.Write("ì‘ë‹µ: ");
    await foreach (var chunk in ollama.CallStreamAsync("í•œêµ­ì–´ë¡œ ê°„ë‹¨íˆ AIë¥¼ ì„¤ëª…í•´ì¤˜ (3ë¬¸ì¥)", "gpt-oss:20b"))
    {
        Console.Write(chunk);
    }
    Console.WriteLine("\n");

    Console.WriteLine("=== Ollama Provider í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===");
}

static async Task TestPromptRegistry(PromptRegistry promptRegistry, ToolRegistry toolRegistry, OllamaProvider ollama)
{
    Console.Clear();
    Console.WriteLine("=== AI Agent Framework - PromptRegistry í…ŒìŠ¤íŠ¸ ===\n");

    Console.WriteLine($"ë“±ë¡ëœ í”„ë¡¬í”„íŠ¸ ìˆ˜: {promptRegistry.GetAllPrompts().Count}");
    foreach (var promptDef in promptRegistry.GetAllPrompts())
    {
        Console.WriteLine($"  - {promptDef.Name} ({promptDef.Role}): {promptDef.Metadata.Description}");
    }
    Console.WriteLine();

    var toolSelectionPrompt = promptRegistry.GetPrompt("tool-selection");
    Console.WriteLine($"í”„ë¡¬í”„íŠ¸: {toolSelectionPrompt?.Template.Substring(0, 100)}...");
    Console.WriteLine($"ë³€ìˆ˜: {string.Join(", ", toolSelectionPrompt?.Variables ?? new List<string>())}\n");

    var variables = new Dictionary<string, object>
    {
        ["TOOLS"] = toolRegistry.GetToolDescriptionsForLLM(),
        ["USER_INPUT"] = "c:\\test-data\\sample.txt íŒŒì¼ì„ ì½ì–´ì¤˜"
    };

    var validation = promptRegistry.ValidateVariables("tool-selection", variables);
    Console.WriteLine($"ë³€ìˆ˜ ê²€ì¦: {(validation.IsValid ? "ì„±ê³µ" : validation.ErrorMessage)}\n");

    var renderedPrompt = toolSelectionPrompt!.Render(variables);

    Console.WriteLine("--- LLM Tool ì„ íƒ í…ŒìŠ¤íŠ¸ ---");
    var toolSelectionResponse = await ollama.CallAsync(renderedPrompt, "llama3.1:8b");
    Console.WriteLine($"LLM ì‘ë‹µ:\n{toolSelectionResponse}\n");

    Console.WriteLine("=== PromptRegistry í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===");
}

static async Task TestToolSelector(PromptRegistry promptRegistry, ToolRegistry toolRegistry, OllamaProvider ollama)
{
    Console.Clear();
    Console.WriteLine("=== AI Agent Framework - ToolSelectorFunction í…ŒìŠ¤íŠ¸ ===\n");

    var toolSelectorFunction = new ToolSelectorFunction(
        promptRegistry,
        ollama,
        toolRegistry
    );

    var context = new LLMContext
    {
        UserInput = "c:\\test-data\\sample.txt íŒŒì¼ì„ ì½ì–´ì¤˜"
    };

    Console.WriteLine($"ì‚¬ìš©ì ìš”ì²­: {context.UserInput}\n");
    Console.WriteLine("--- ToolSelectorFunction ì‹¤í–‰ ì¤‘... ---\n");

    var llmResult = await toolSelectorFunction.ExecuteAsync(context);
    var toolSelection = (ToolSelectionResult)llmResult.ParsedData!;

    Console.WriteLine($"ì„ íƒëœ Tool: {toolSelection.ToolName}");
    Console.WriteLine($"íŒŒë¼ë¯¸í„°: {toolSelection.Parameters}");
    Console.WriteLine($"LLM Role: {llmResult.Role}");
    Console.WriteLine($"ì›ë³¸ ì‘ë‹µ:\n{llmResult.RawResponse}\n");

    Console.WriteLine("=== ToolSelectorFunction í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===");
}

static async Task TestStreaming(PromptRegistry promptRegistry, ToolRegistry toolRegistry, OllamaProvider ollama)
{
    Console.Clear();
    Console.WriteLine("=== AI Agent Framework - Streaming í…ŒìŠ¤íŠ¸ ===\n");

    var streamingOptions = new LLMFunctionOptions
    {
        ModelName = "gpt-oss:20b",
        EnableStreaming = true,
        TimeoutMs = 60000
    };

    var streamingToolSelector = new ToolSelectorFunction(
        promptRegistry,
        ollama,
        toolRegistry,
        streamingOptions
    );

    Console.WriteLine($"ìŠ¤íŠ¸ë¦¬ë° ì§€ì›: {streamingToolSelector.SupportsStreaming}");
    Console.WriteLine($"ëª¨ë¸: {streamingOptions.ModelName}\n");

    var streamingContext = new LLMContext
    {
        UserInput = "ì•ˆë…•ì´ë¼ê³  ë©”ì‹œì§€ ì¶œë ¥í•´ì¤˜"
    };

    Console.WriteLine($"ì‚¬ìš©ì ìš”ì²­: {streamingContext.UserInput}\n");
    Console.WriteLine("--- ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìˆ˜ì‹  ì¤‘... ---");
    Console.Write("ì‘ë‹µ: ");

    var fullResponse = new StringBuilder();
    await foreach (var chunk in streamingToolSelector.ExecuteStreamAsync(streamingContext))
    {
        if (!chunk.IsFinal && !string.IsNullOrEmpty(chunk.Content))
        {
            Console.Write(chunk.Content);
            fullResponse.Append(chunk.Content);
        }
        else if (chunk.IsFinal)
        {
            Console.WriteLine($"\n\nëˆ„ì  í† í°: {chunk.AccumulatedTokens}");
            Console.WriteLine($"ì´ ì²­í¬ ìˆ˜: {chunk.Index}");
        }
    }

    Console.WriteLine("\n\n=== Streaming í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===");
}

static async Task TestTaskPlanner(PromptRegistry promptRegistry, ToolRegistry toolRegistry, LLMRegistry llmRegistry, OllamaProvider ollama)
{
    Console.Clear();
    Console.WriteLine("=== AI Agent Framework - TaskPlanner í…ŒìŠ¤íŠ¸ ===\n");

    var taskPlanner = new TaskPlannerFunction(
        promptRegistry,
        ollama,
        toolRegistry,
        llmRegistry
    );

    var planningContext = new LLMContext
    {
        UserInput = "c:\\test-data í´ë”ì˜ ëª¨ë“  txt íŒŒì¼ì„ ì½ê³ , ê° íŒŒì¼ì˜ ë‚´ìš©ì„ ìš”ì•½í•œ ë‹¤ìŒ, ê²°ê³¼ë¥¼ summary.md íŒŒì¼ë¡œ ì €ì¥í•´ì¤˜"
    };

    Console.WriteLine($"ì‚¬ìš©ì ìš”ì²­: {planningContext.UserInput}\n");
    Console.WriteLine("--- TaskPlanner ì‹¤í–‰ ì¤‘... ---\n");

    var planResult = await taskPlanner.ExecuteAsync(planningContext);
    var plan = (PlanningResult)planResult.ParsedData!;

    Console.WriteLine($"ğŸ“‹ ê³„íš ìš”ì•½: {plan.Summary}\n");
    Console.WriteLine($"âœ… ì‹¤í–‰ ê°€ëŠ¥: {plan.IsExecutable}");
    Console.WriteLine($"â±ï¸  ì˜ˆìƒ ì‹œê°„: {plan.TotalEstimatedSeconds}ì´ˆ\n");

    if (plan.Steps.Count > 0)
    {
        Console.WriteLine("ğŸ“ ì‹¤í–‰ ë‹¨ê³„:");
        foreach (var step in plan.Steps)
        {
            Console.WriteLine($"\n  [{step.StepNumber}] {step.Description}");
            Console.WriteLine($"      Tool: {step.ToolName}");
            Console.WriteLine($"      Parameters: {step.Parameters}");
            if (!string.IsNullOrEmpty(step.OutputVariable))
            {
                Console.WriteLine($"      Output â†’ {step.OutputVariable}");
            }
            if (step.DependsOn.Count > 0)
            {
                Console.WriteLine($"      Depends on: {string.Join(", ", step.DependsOn)}");
            }
            if (step.EstimatedSeconds.HasValue)
            {
                Console.WriteLine($"      Est. time: {step.EstimatedSeconds}ì´ˆ");
            }
        }
    }

    if (plan.Constraints.Count > 0)
    {
        Console.WriteLine($"\nâš ï¸  ì œì•½ì‚¬í•­:");
        foreach (var constraint in plan.Constraints)
        {
            Console.WriteLine($"  - {constraint}");
        }
    }

    if (!plan.IsExecutable && !string.IsNullOrEmpty(plan.ExecutionBlocker))
    {
        Console.WriteLine($"\nâŒ ì‹¤í–‰ ë¶ˆê°€ ì´ìœ :\n{plan.ExecutionBlocker}");
    }

    Console.WriteLine($"\n\nì›ë³¸ LLM ì‘ë‹µ:\n{planResult.RawResponse}\n");

    Console.WriteLine("=== TaskPlanner í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===");
}
